num_training_steps: 1000
micro_batch_size: 1
dp: 8
gradient_accumulation_steps: 8
seq_length: 4096
megatron_dataset_flag: False
data_path: 'xxx'
save_dir: 'xxx'
save_interval: 10000
eval_interval: 10000
openmind_model_path: 'xxx'
dtype: 'bf16'

dataloader_config:
  return_tensors: 'pt'
  padding: 'max_length'
  pad_to_multiple_of: 4096
  max_length: 4096
